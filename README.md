# Какой итоговый продукт вы видите

Итоговый продукт - приложение, которое позволяет сохранять и структурировать веб-ссылки, с возможностью предпросмотра страницы в оффлайне и ее архивирования(версионность). А так же с возможностью создания совместных проектов

Приложение будет сохранять веб-страницы, указанных веб-ссылок, отправляя их на сервер(можно сделать вручную по нажатию кнопки). Раз в месяц(можно настраивать) будут производиться автомотические слепки страниц.
 
На сохраненных страницах можно будет делать пометки: выделять текст цветом. Все это будет синхронизированно с другими пользователями проекта.

Будет возможность создавать проекты и добавлять в них других пользователей по специальному идентификатору.

Будет возможность авторизироваться и регистрироваться.

# На какую аудиторию рассчитан:

Пользователи сети интернет, которым требуется сохрянять много ссылок, творчиские личности, которым нужно сохранять много эскизов, художников, работ, которые заинтересовали, для журналистов и блогеров, которым требуется отследить изменения страницы за какой-то промежуток времени. Семьям, которые хотят совместно подойти к вопросу покупки каких-либо бытовых решений и т.п.

# Какие аналоги существуют. Хорошо ли вы понимаете, как они устроены:

- Raindrop.io
- Bookmark Ninja
- Save to Pocket
- Evernote
- Pinboard
- Diigo
- Google Bookmarks
- Dewey Bookmarks
- iCloud Bookmarks
- Toby

# Из каких компонентов состоит ваш проект

- Сервер - содержит слепки, синхронизирует клиентов, содержит информацию о сессиях, БД, ссылки
- Клиент - отображение ссылок, создание комнат, папок, превью страниц
- Гуи
- Авторизация
- webview
- Органайзер
- crawler с возможностью архивирования страниц
- scraper

# Задача-минимум (MVP), задача-оптимум и задача-максимум - какие задачи туда входят:

- MVP:

  Общие данные для всех клиентов(нет аутентификации)

  Слепки страниц, 

  сохранение ссылок, 

  создание комнат, 

  сделать слепок по кнопке,
  
  сервер создает слепок по настраиваемому времени

  комментарии к ссылкам и названия

  web crawler
  
  БД

- Оптимум:

  ГУИ клиент

  предосмотр, 

  авторизация

  создание закрытых комнат

  добавление пользователей в закрытую комнату

  web scraper

- Максимум:

  добавление пометок(подчеркивание/выделение цветом) на слепки страниц

  автоматическое создание нового слепка при появлении изменений на странице 

  отображение видео

  добавление тегов для ссылок и поиск по ним

# Как бы вы подошли к разработке, если бы "до защиты осталась неделя" - всегда должно быть примерное понимание какого-то "базового варианта реализации", чтобы от него отталкиваться

На сервере расположен HTTP сервер, который предоставляет апи для управления данными(ссылками), апи для создания комнат, а так же апи для создания слепков. На клиенте при добавлении ссылки мы отправляем запрос на сервер на слепок и сохраняем ссылку на сервере. Далее сервер отсылает нужные данные клиенту и слепки складируются в какую-то папку. После этого их можно будет открыть оффлайн через браузер или просто открыть ссылку в онлайне. Так же при написании спец. команды для клиента мы сможем сделать слепок вручную.

# Какой подход, технологии использовали бы:

http server, QT, web crawler, web scrapper

# План проекта "по уму"

http server, реализация основных API, rooms/, rooms/id/links/, links/id/snapshots, users/, auth/

web crawler, слепки страниц

слепок по настраиваемому времени, создание слепка по команде

-----

Авторизация

Создание закрытых комнат, добавление пользователей в эти комнаты

web scraper

ГУИ клиент + предосмотр

-----

добавление пометок(подчеркивание/выделение цветом) на слепки страниц

добавление тегов для ссылок и поиск по ним

автоматическое создание нового слепка при появлении изменений на странице 

отображение видео

# Как оцените результат итоговой работы - должны быть какие-то критерии завершённости и успеха/метрики качества

- Добавляемые ссылки, добавляются дрюгим юзерам комнаты
- Добавляемые ссылки не теряются
- Слепки страницы соответсвуют ей
- Превью соответствует веб-странице, открытой в браузере
